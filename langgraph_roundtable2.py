import operator
import json
import traceback
from typing import TypedDict, Annotated, List, Dict, Union
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph_main2 import GraphAgent, eval_func
from color_print import gov_print, dev_print, village_print
from prompt import cfg
NEXT_ROUND = "NEXT_ROUND"

printer = {"Government": gov_print, "Developer": dev_print, "Village": village_print}

# --- å¯¼å…¥æ‚¨ç°æœ‰çš„æ¨¡å— ---
# ç¡®ä¿è¿™äº›æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹
from agent import ReflectiveAgent
from llm_model import llm
from prompt import (
    WORLD_CONTEXT,
    AGENT_GOV_PROMPT,
    AGENT_DEV_PROMPT,
    AGENT_VILLAGE_PROMPT,
    prompt_template
)

runtime_config = {
    "recursion_limit": cfg['max_node_jump_steps']
}


# --- 1. å®šä¹‰å›¾çš„çŠ¶æ€ (State) ---
class RoundTableState(TypedDict):
    """
    åœ†æ¡Œä¼šè®®çš„å…¨å±€çŠ¶æ€
    """
    # ä¼šè®®å†å²ï¼šå­˜å‚¨æ‰€æœ‰çš„å‘è¨€è®°å½•
    history: Annotated[List[BaseMessage], operator.add]
    # å½“å‰è½®æ¬¡
    current_round: int
    # æ€»è½®æ¬¡é™åˆ¶
    total_round: int
    # æ‰€æœ‰äººéƒ½åŒæ„å½“å‰æ–¹æ¡ˆ
    all_agree: bool
    # æœ€æ–°ç”Ÿæ•ˆçš„å†³ç­–å‘é‡ (ç”¨äº Prompt ä¸­æç¤ºå½“å‰çŠ¶æ€)
    latest_vector: List[float]
    # ä¸Šä¸€ä½å‘è¨€è€… (ç”¨äº Prompt ä¸Šä¸‹æ–‡)
    last_speaker: str
    # ææ¡ˆæ—¥å¿— (ç”¨äºæœ€ç»ˆç»Ÿè®¡)
    proposals_log: Annotated[List[Dict], operator.add]
    pareto_records: Annotated[List[Dict], operator.add]


# --- 2. åˆå§‹åŒ– Agents ---
# ç›´æ¥å¤ç”¨ agent.py ä¸­çš„ ReflectiveAgent ç±»
# æˆ‘ä»¬åœ¨è¿™é‡Œå®ä¾‹åŒ–å®ƒä»¬ï¼Œä½œä¸ºå›¾çš„é™æ€èµ„æº
agent_configs = {
    "Government": WORLD_CONTEXT + AGENT_GOV_PROMPT,
    "Developer": WORLD_CONTEXT + AGENT_DEV_PROMPT,
    "Village": WORLD_CONTEXT + AGENT_VILLAGE_PROMPT
}

# # åˆ›å»ºä¸‰ä¸ª ReflectiveAgent å®ä¾‹
# agents_map = {
#     name: ReflectiveAgent(name, llm, system_prompt, math_core.evaluate_proposal)
#     for name, system_prompt in agent_configs.items()
# }

langgraph_agents = {role: GraphAgent(role, metric=cfg['target']) for role in agent_configs}


# --- 3. å®šä¹‰é€šç”¨èŠ‚ç‚¹é€»è¾‘ ---

def run_role_node(state: RoundTableState, role_name: str):
    printer[role_name](f"\nğŸ¤ --- è½®åˆ° {role_name} å‘è¨€ (ç¬¬ {state['current_round']} è½®) ---")
    printer[role_name](f"[å½“å‰å†³ç­–å‘é‡]: {state['latest_vector']}")
    new_messages = langgraph_agents[role_name].invoke(state['latest_vector'])

    # è®°å½•å¸•ç´¯æ‰˜è®°å½•
    try:
        eval_result = eval_func(*new_messages['latest_vector'])
        utilities = eval_result['utilities']
    except KeyError:
        print('ç¼ºå°‘utilitieså­—æ®µ', eval_result)
        utilities = eval_func(*state['latest_vector'])
    pareto_entry = {
        'utilities': utilities,
        'delta': new_messages['latest_vector'][3]
    }

    updates = dict(history=new_messages['messages'], last_speaker=role_name,
                   latest_vector=new_messages['latest_vector'], pareto_records=[pareto_entry])

    return updates


# def run_role_node(state: RoundTableState, role_name: str):
#     """
#     é€šç”¨çš„è§’è‰²èŠ‚ç‚¹æ‰§è¡Œå‡½æ•°ã€‚
#     å®ƒè´Ÿè´£å°†å›¾çš„çŠ¶æ€è½¬æ¢ä¸º ReflectiveAgent éœ€è¦çš„è¾“å…¥ï¼Œå¹¶å¤„ç†è¾“å‡ºã€‚
#     """
#     agent = agents_map[role_name]
#
#     print(f"\nğŸ¤ --- è½®åˆ° {role_name} å‘è¨€ (ç¬¬ {state['current_round']} è½®) ---")
#
#     # 1. å‡†å¤‡ Prompt
#     # æˆ‘ä»¬éœ€è¦æŠŠ BaseMessage åˆ—è¡¨è½¬æ¢ä¸º prompt_template éœ€è¦çš„å­—ç¬¦ä¸²æ ¼å¼
#     # è¿™é‡Œæ¨¡æ‹Ÿäº† agent.py ä¸­ RoundTableLLM._format_history çš„é€»è¾‘
#     history_text = "\n".join([
#         f"{msg.name if hasattr(msg, 'name') else msg.type}: {msg.content}"
#         for msg in state['history'][-6:]  # åªå–æœ€è¿‘å‡ æ¡ï¼Œé¿å… token è¿‡é•¿
#     ])
#
#     # æ·»åŠ å½“å‰æœ€æ–°çš„æ–¹æ¡ˆä¿¡æ¯
#     current_status_str = f"{state.get('last_speaker', 'ä¸»æŒäºº')} æå‡ºçš„æœ€æ–°å†³ç­–å‘é‡ä¸º {state['latest_vector']}"
#     full_history_str = f"{history_text}\n{current_status_str}"
#
#     # ä½¿ç”¨ prompt.py ä¸­çš„æ¨¡æ¿æ ¼å¼åŒ–
#     formatted_prompt = prompt_template.format(
#         round=state['current_round'],
#         total_round=state['total_round'],
#         history=full_history_str
#     )
#
#     # 2. è°ƒç”¨ Agent
#     # ReflectiveAgent.propose å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç† "æè®®-æ ¡éªŒ-ä¿®æ­£" å¾ªç¯
#     # æˆ‘ä»¬å°†æ ¼å¼åŒ–å¥½çš„ Prompt åŒ…è£…ä¸º HumanMessage ä¼ å…¥
#     response = agent.propose([HumanMessage(content=formatted_prompt)])
#
#     # 3. å¤„ç†ç»“æœå¹¶æ›´æ–°çŠ¶æ€
#     action_model = response['action_model']
#     evaluation = response['evaluation']
#
#     new_messages = []
#     updates = {}
#
#     # è®°å½• Agent çš„å…¬å¼€å–Šè¯
#     speech_content = action_model.public_speech
#     new_messages.append(AIMessage(content=speech_content, name=role_name))
#
#     if evaluation:
#         # å¦‚æœæå‡ºäº†æ–°æ–¹æ¡ˆä¸”é€šè¿‡æ ¡éªŒ
#         new_vector = action_model.new_proposal_vector
#         updates['latest_vector'] = new_vector
#         updates['proposals_log'] = [response]
#
#         # æ·»åŠ ç³»ç»Ÿå…¬è¯ä¿¡æ¯
#         sys_msg = (
#             f"[ç³»ç»Ÿå…¬è¯]: {role_name} æå‡ºäº†æ–°æ–¹æ¡ˆ {new_vector}ã€‚\n"
#             f"è¯„ä¼°æŒ‡æ ‡: WSWM={evaluation['utilities']['WSWM']}, "
#             f"U_G={evaluation['utilities']['U_G']}, "
#             f"U_D={evaluation['utilities']['U_D']}, "
#             f"U_V={evaluation['utilities']['U_V']}"
#         )
#         print(sys_msg)  # æ§åˆ¶å°æ‰“å°
#         new_messages.append(SystemMessage(content=sys_msg))
#     else:
#         # å¦‚æœæ¥å—äº†æ–¹æ¡ˆæˆ–æ²¡ææ–°æ–¹æ¡ˆ
#         print(f"[{role_name}] æœªæå‡ºæœ‰æ•ˆæ–°æ–¹æ¡ˆ (ç»´æŒç°çŠ¶)")
#
#     updates['history'] = new_messages
#     updates['last_speaker'] = role_name
#
#     return updates


# --- 4. å®šä¹‰å…·ä½“èŠ‚ç‚¹ ---
# LangGraph éœ€è¦å…·ä½“çš„å‡½æ•°ä½œä¸ºèŠ‚ç‚¹

def government_node(state: RoundTableState):
    return run_role_node(state, "Government")


def developer_node(state: RoundTableState):
    return run_role_node(state, "Developer")


def village_node(state: RoundTableState):
    return run_role_node(state, "Village")


def round_manager_node(state: RoundTableState):
    """
    ç®¡ç†è½®æ¬¡çš„èŠ‚ç‚¹
    """
    new_round = state['current_round'] + 1
    return {"current_round": new_round}


def summary_node(state: RoundTableState):
    """
    æ€»ç»“æ‰€æœ‰äººçš„æ”¹åŠ¨æ„è§ï¼Œç»“åˆè§’è‰²çš„è¯è¯­æƒï¼Œæ€»ç»“æ–°çš„æ–¹æ¡ˆå‘é‡
    """
    pass


def check_continuation(state: RoundTableState):
    """
    æ¡ä»¶è¾¹é€»è¾‘ï¼šåˆ¤æ–­æ˜¯ç»§ç»­è¿˜æ˜¯ç»“æŸ
    """
    if state['all_agree']:
        print("\nğŸ‰ æ‰€æœ‰äººåŒæ„ï¼Œç»“æŸä¼šè®®ã€‚")
        return END
    elif state['current_round'] > state['total_round']:
        print("\nğŸ›‘ ä¼šè®®è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œç»“æŸã€‚")
        return END
    else:
        print(f"\nğŸ”„ è¿›å…¥ç¬¬ {state['current_round']} è½®...")
        return NEXT_ROUND  # ä¸‹ä¸€è½®


# --- 5. æ„å»ºå›¾ (Graph) ---

workflow = StateGraph(RoundTableState)

# æ·»åŠ èŠ‚ç‚¹
workflow.add_node("Government", government_node)
workflow.add_node("Developer", developer_node)
workflow.add_node("Village", village_node)
workflow.add_node("RoundManager", round_manager_node)

# è®¾ç½®å…¥å£
workflow.set_entry_point("Government")

# æ·»åŠ è¾¹ (å®šä¹‰å‘è¨€é¡ºåº)
workflow.add_edge("Government", "Developer")
workflow.add_edge("Developer", "Village")
workflow.add_edge("Village", "RoundManager")  # æ‘æ°‘å‘è¨€åï¼Œè¿›å…¥è½®æ¬¡ç®¡ç†

# æ·»åŠ æ¡ä»¶è¾¹ (åˆ¤æ–­å¾ªç¯)
workflow.add_conditional_edges(
    "RoundManager",
    check_continuation,
    {
        NEXT_ROUND: "Government",  # ç»§ç»­å¾ªç¯
        END: END  # ç»“æŸ
    }
)

# ç¼–è¯‘å›¾
app = workflow.compile()

# --- 6. è¿è¡Œä¸»ç¨‹åº ---

if __name__ == "__main__":

    print("--- ğŸš€ LangGraph åœ†æ¡Œä¼šè®®å¯åŠ¨ ---")
    baseline_vector = cfg['baseline_vector']

    # åˆå§‹çŠ¶æ€
    initial_state = {
        "history": [
            SystemMessage(content="ä¸»æŒäºº: ä¼šè®®å¼€å§‹ã€‚è¯·å„æ–¹åŸºäºåŸºå‡†æ–¹æ¡ˆå‘è¡¨æ„è§ã€‚")
        ],
        "current_round": 1,
        "total_round": cfg['max_round'],  # è®¾å®šè®¨è®ºè½®æ•°
        "latest_vector": baseline_vector,
        "last_speaker": "ä¸»æŒäºº",
        "proposals_log": [],
        "pareto_records": []
    }

    # è¿è¡Œå›¾
    # # ä½¿ç”¨ .stream() å¯ä»¥å®æ—¶çœ‹åˆ°æ¯ä¸€æ­¥çš„è¾“å‡º
    # for s in app.stream(initial_state):
    #     # è¿™é‡Œå¯ä»¥æ‰“å°æ¯ä¸€æ­¥çš„çŠ¶æ€æ›´æ–°ï¼Œç”¨äºè°ƒè¯•
    #     print(s)
    discuss_result = app.invoke(initial_state, config=runtime_config)

    print("\n--- âœ… ä¼šè®®ç»“æŸ ---")
    # å¯ä»¥ä»æœ€ç»ˆçŠ¶æ€ä¸­æå–ç»“æœï¼ˆå¦‚æœæœ‰åŠæ³•è·å–æœ€ç»ˆçŠ¶æ€å¯¹è±¡ï¼‰
    # ç”±äº stream è¿­ä»£å®Œï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦æŠŠ final state å­˜ä¸‹æ¥ï¼Œæˆ–è€…åªçœ‹æ‰“å°æ—¥å¿—
    with open(f'result_{cfg["target"]}.json', 'w') as f:
        if 'history' in discuss_result:
            discuss_result.pop('history')
        json.dump(discuss_result, f)
