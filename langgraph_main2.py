import functools
import json
import operator
from typing import TypedDict, Annotated, List, Optional, Literal
from pydantic import BaseModel, Field

from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, AIMessage, BaseMessage
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from agent import ReflectiveAgent
from llm_model import llm
from utils import post_process_deepseek_response
from prompt import WORLD_CONTEXT, AGENT_DEV_PROMPT, AGENT_GOV_PROMPT, AGENT_VILLAGE_PROMPT, prompt_template, cfg
import LLM_optimization as math_core

agent_characters = {"Government": WORLD_CONTEXT + AGENT_GOV_PROMPT,
                    "Developer": WORLD_CONTEXT + AGENT_DEV_PROMPT,
                    "Village": WORLD_CONTEXT + AGENT_VILLAGE_PROMPT}

if cfg['target'] == 'WSWM':
    eval_func = math_core.evaluate_proposal
elif cfg['target'] == 'wNBS':
    eval_func = functools.partial(math_core.evaluate_wNBS,
                                  utility_lower_bound=cfg['utility_lb'],
                                  strength=cfg['strength'])
else:
    eval_func = None
    print("[è­¦å‘Š]: æœªå®šä¹‰ç›®æ ‡å‡½æ•°ã€‚è¯·æ£€æŸ¥æ‚¨çš„é…ç½®æ–‡ä»¶ã€‚")

agents = {name: ReflectiveAgent(name, llm, system_prompt, eval_func) for name, system_prompt in
          agent_characters.items()}


# --- 1. å®šä¹‰å·¥å…· (Agent çš„ "æ‰‹è„š") ---
@tool
def evaluate_objective_function(input_vector: List[float], metric: Literal['WSWM', 'wNBS']) -> float:
    """
    è°ƒç”¨ç›®æ ‡å‡½æ•° (ä¾‹å¦‚ WSWM) æ¥è¯„ä¼°ç»™å®šå‘é‡çš„åˆ†æ•°ã€‚
    åˆ†æ•°è¶Šé«˜è¶Šå¥½ã€‚
    """
    print(f"   [å·¥å…·]: æ­£åœ¨è¯„ä¼°å‘é‡ {input_vector}...")
    try:
        # å‡è®¾æˆ‘ä»¬ä½¿ç”¨ run_optimization.py ä¸­çš„é€»è¾‘
        # æˆ‘ä»¬éœ€è¦ä»Ž eval_func èŽ·å–åˆ†æ•°
        # æ³¨æ„ï¼šæ‚¨çš„ eval_func éœ€è¦5ä¸ªæµ®ç‚¹æ•°
        if len(input_vector) != 5:
            return -999.9  # è¿”å›žä¸€ä¸ªæ— æ•ˆåˆ†æ•°

        eval_result = eval_func(
            AR=input_vector[0],
            AC=input_vector[1],
            AO=input_vector[2],
            Delta=input_vector[3],
            Tau=input_vector[4]
        )
        if eval_result["status"] == "ACCEPTED":
            score = float(eval_result["utilities"][metric])
            print(f"   [å·¥å…·]: å‘é‡ {input_vector} çš„ {metric} åˆ†æ•°æ˜¯: {score}")
            return score
        else:
            print(f"   [å·¥å…·]: å‘é‡ {input_vector} å› ä¸åˆè§„è¢«æ‹’ç»ã€‚")
            return -999.9  # è¿”å›žä¸€ä¸ªæžä½Žçš„åˆ†æ•°
    except Exception as e:
        print(f"   [å·¥å…·]: è¯„ä¼°å¤±è´¥: {e}")
        return -999.9


# å·¥å…·Bï¼šLLM ç”¨å®ƒæ¥æäº¤æ–°æ–¹æ¡ˆ
class ProposeNewVector(BaseModel):
    """ç”¨äºŽæäº¤ä¸€ä¸ªæ–°ä¼˜åŒ–æ–¹æ¡ˆçš„å·¥å…·ã€‚"""
    input_vector: List[float] = Field(description="å½“å‰å†³ç­–å‘é‡ã€‚")
    score_old: float = Field(description="å½“å‰å†³ç­–å‘é‡çš„è¯„åˆ†ã€‚")
    role_name: str = Field(description="å½“å‰ç”¨æˆ·è§’è‰²ã€‚")
    # messages: List[BaseMessage] = Field(description="åŽ†å²ä¿¡æ¯ã€‚")


@tool(args_schema=ProposeNewVector)
def propose_new_vector(role_name: str, input_vector: List[float], score_old: float):
    """
    é€‰æ‹©ç”¨æˆ·è§’è‰²ï¼Œå¯¹å½“å‰æƒ…å†µæå‡ºæ–°çš„å‘é‡æ–¹æ¡ˆ
    """
    situation_message = prompt_template.format(history=f"å½“å‰æ–¹æ¡ˆæ˜¯ä¸ºè¯„åˆ†ä¸º{score_old:.4f}çš„å†³ç­–å‘é‡{input_vector}",
                                               round=round, total_round=5)
    # situation_message = SystemMessage(content=)
    response = agents[role_name].propose([situation_message])
    # todo: add thought process
    if response['evaluation']:
        return json.dumps({'score_new': response['evaluation']['utilities'][cfg['target']],
                           'new_vector': response['action_model'].new_proposal_vector})
    else:
        return "æœªæå‡ºæœ‰æ•ˆæ–¹æ¡ˆ"


# å·¥å…·Cï¼šLLM ç”¨å®ƒæ¥ç»“æŸä»»åŠ¡
class FinalDecisionSchema(BaseModel):
    """ç”¨äºŽåšå‡ºæœ€ç»ˆå†³ç­–å¹¶ç»“æŸä¼˜åŒ–æµç¨‹"""
    decision: str = Field(description="'accept_new' (æŽ¥å—æ–°æ–¹æ¡ˆ) æˆ– 'reject_new' (ç»´æŒæ—§æ–¹æ¡ˆ)")
    justification: str = Field(description="åšå‡ºæ­¤å†³ç­–çš„æœ€ç»ˆç†ç”±ã€‚")
    final_vector: List[float] = Field(description="æœ€ç»ˆé€‰å®šçš„å‘é‡ã€‚")


@tool(args_schema=FinalDecisionSchema)
def final_decision(decision: str, justification: str, final_vector: List[float]):
    """
    ç”¨äºŽåšå‡ºæœ€ç»ˆå†³ç­–å¹¶ç»“æŸä¼˜åŒ–æµç¨‹çš„å·¥å…·ã€‚
    è°ƒç”¨æ­¤å·¥å…·æ ‡å¿—ç€ä¼˜åŒ–ä»»åŠ¡çš„å®Œæˆã€‚
    """
    # è¿™é‡Œæ˜¯å·¥å…·è¢«è°ƒç”¨æ—¶çš„æ‰§è¡Œé€»è¾‘
    # åœ¨ LangGraph ä¸­ï¼Œè¿™é€šå¸¸åªæ˜¯æ‰“å°æ—¥å¿—æˆ–è¿”å›žä¸€ä¸ªç¡®è®¤å­—ç¬¦ä¸²
    print(f"\n--- ðŸ Agent æäº¤äº†æœ€ç»ˆå†³ç­– ---")
    print(f"å†³ç­–: {decision}")
    print(f"ç†ç”±: {justification}")
    print(f"æœ€ç»ˆå‘é‡: {final_vector}")

    # è¿”å›žå€¼ä¼šä½œä¸º ToolMessage å›žä¼ ç»™ LLM (è™½ç„¶é€šå¸¸æµç¨‹åœ¨æ­¤ç»“æŸ)
    return f"ä»»åŠ¡ç»“æŸã€‚å†³ç­–: {decision}, æœ€ç»ˆå‘é‡: {final_vector}"


# --- 2. å®šä¹‰ Agent å’Œå·¥å…·æ‰§è¡Œå™¨ ---

# æ³¨å†Œæ‰€æœ‰å·¥å…·
tools = [evaluate_objective_function, propose_new_vector, final_decision]
tools_map = {t.name: t for t in tools}

# å®šä¹‰ Agent (LLM + ç»‘å®šå·¥å…·)
# æˆ‘ä»¬å°†ä½¿ç”¨ PydanticToolsParserï¼Œæ‰€ä»¥ LLM å¯ä»¥è‡ªç”±é€‰æ‹©å·¥å…·
llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=False)

# --- 3. å®šä¹‰ Agent çš„â€œå¤§è„‘â€ (System Prompt) ---
# è¿™æ˜¯æœ€å…³é”®çš„éƒ¨åˆ†ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œå®šä¹‰äº†æ‚¨çš„ç®—æ³•ï¼

OPTIMIZER_SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€ä¸ªâ€œä¼˜åŒ–å™¨ Agentâ€ã€‚ä½ çš„ç›®æ ‡æ˜¯æŽ¥æ”¶ä¸€ä¸ªè¾“å…¥å‘é‡ï¼Œæå‡ºä¸€ä¸ªæ–°å‘é‡ï¼Œå¹¶åˆ¤æ–­æ–°å‘é‡æ˜¯å¦åœ¨â€œç›®æ ‡å‡½æ•°â€ä¸Šå–å¾—äº†æ›´å¥½çš„åˆ†æ•°ã€‚

ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ‰§è¡Œï¼š

1.  **æŽ¥æ”¶è¾“å…¥**ï¼šç”¨æˆ·ä¼šæä¾›ä¸€ä¸ª `input_vector`ã€‚
2.  **è¯„ä¼°æ—§æ–¹æ¡ˆ**ï¼šä½  *å¿…é¡»* é¦–å…ˆè°ƒç”¨ `evaluate_objective_function` å·¥å…·æ¥èŽ·å– `input_vector` çš„åˆ†æ•°ï¼ˆ`score_old`ï¼‰ã€‚
3.  **æå‡ºæ–°æ–¹æ¡ˆ**ï¼šåœ¨èŽ·å¾— `score_old` åŽï¼Œä½  *å¿…é¡»* åˆ†æž `input_vector` å’Œ `score_old`ï¼Œç„¶åŽè°ƒç”¨ `propose_new_vector` ã€‚
    è¯¥å·¥å…·ä¼šè¿”å›ž **æ–°å‘é‡ (`new_vector`)** ä»¥åŠ **æ–°åˆ†æ•° (`score_new`)**ã€‚
    * æ³¨æ„ï¼šä½  **ä¸éœ€è¦** å†æ¬¡è°ƒç”¨è¯„ä¼°å·¥å…·ï¼Œç›´æŽ¥ä½¿ç”¨å·¥å…·è¿”å›žçš„ `score_new`ã€‚
4.  **åšå‡ºå†³ç­–**ï¼šåœ¨åŒæ—¶æ‹¥æœ‰ `score_old` å’Œ `score_new` åŽï¼Œä½  *å¿…é¡»* æ¯”è¾ƒå®ƒä»¬ã€‚
    * å¦‚æžœ `score_new > score_old`ï¼Œè¯´æ˜Žæ–°æ–¹æ¡ˆæ›´å¥½ã€‚
    * å¦‚æžœ `score_new <= score_old`ï¼Œè¯´æ˜Žæ–°æ–¹æ¡ˆæ²¡æœ‰æå‡æˆ–æ›´å·®ã€‚
5.  **ç»“æŸ**ï¼šä½  *å¿…é¡»* è°ƒç”¨ `final_decision` å·¥å…·æ¥ç»“æŸä»»åŠ¡ï¼Œæ˜Žç¡®è¯´æ˜Žä½ æŽ¥å—è¿˜æ˜¯æ‹’ç»æ–°æ–¹æ¡ˆï¼Œå¹¶é™„ä¸Šç†ç”±ã€‚

ä¸è¦è·³è¿‡ä»»ä½•æ­¥éª¤ã€‚

ã€final_decision è°ƒç”¨è§„èŒƒã€‘
åªæœ‰åœ¨æ‹¥æœ‰ `score_old` å’Œ `score_new` ä¸¤ä¸ªåˆ†æ•°å¹¶å®Œæˆæ¯”è¾ƒåŽï¼Œæ‰èƒ½è°ƒç”¨ `final_decision`ã€‚
è°ƒç”¨æ—¶å¿…é¡»ä¸¥æ ¼å¡«å……ä»¥ä¸‹å­—æ®µï¼š
- decision: å¿…é¡»æ˜¯ 'accept_new' æˆ– 'reject_new' å­—ç¬¦ä¸²ã€‚
- final_vector: å¿…é¡»æ˜¯ä¸€ä¸ª 5 ç»´æµ®ç‚¹æ•°åˆ—è¡¨ã€‚
- justification: å¿…é¡»åŒ…å«ä¸¤ä¸ªåˆ†æ•°çš„å…·ä½“æ•°å€¼å¯¹æ¯”ï¼ˆä¾‹å¦‚ "æ–°æ–¹æ¡ˆåˆ†æ•° 0.95 é«˜äºŽæ—§æ–¹æ¡ˆ 0.88"ï¼‰ã€‚

ã€é‡è¦æ ¼å¼æŒ‡ä»¤ã€‘
1. ä½ å¿…é¡»ä¸”åªèƒ½ç”Ÿæˆ Tool Callã€‚
2. **ç¦æ­¢å¹¶è¡Œè°ƒç”¨**ï¼šä½ æ¯æ¬¡å›žå¤ **å¿…é¡»ä¸”åªèƒ½** è°ƒç”¨ **1 ä¸ª** å·¥å…·ã€‚
3. **ä¸¥ç¦**ç”Ÿæˆä»»ä½•è‡ªç„¶è¯­è¨€æ–‡æœ¬æˆ–â€œæ€è€ƒè¿‡ç¨‹â€ã€‚
4. **ä¸¥ç¦**åœ¨ content å­—æ®µä¸­è¾“å‡º JSONï¼Œå¿…é¡»ä½¿ç”¨æ ‡å‡†çš„ function calling åè®®ã€‚
5. å¦‚æžœä½ è¾“å‡ºçº¯æ–‡æœ¬ï¼Œä»»åŠ¡å°†ç›´æŽ¥å¤±è´¥ã€‚
"""


# --- 4. å®šä¹‰å›¾çš„çŠ¶æ€ (GraphState) ---

class GraphState(TypedDict):
    """
    GraphState æ˜¯å›¾çš„â€œå†…å­˜â€ã€‚
    'messages' å°†åŒ…å«æ‰€æœ‰çš„å¯¹è¯åŽ†å²ã€‚
    """
    messages: Annotated[List[BaseMessage], operator.add]


# --- 5. å®šä¹‰å›¾çš„èŠ‚ç‚¹å’Œè¾¹ ---

def agent_node(state: GraphState):
    """
    Agent èŠ‚ç‚¹ï¼šè°ƒç”¨ LLM (å¤§è„‘)
    """
    print(f"--- ðŸ§  Agent æ­£åœ¨æ€è€ƒ... ---")
    llm_forced = llm_with_tools.bind(tool_choice='required')
    response = llm_forced.invoke(state["messages"])
    response = post_process_deepseek_response(response)
    # print(response.content)
    return {"messages": [response]}


def tool_node(state: GraphState):
    """
    Tool èŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…· (æ‰‹è„š)
    """
    print(f"--- ðŸ› ï¸ Agent æ­£åœ¨è¡ŒåŠ¨... ---")
    # èŽ·å– LLM åˆšåˆšçš„å›žå¤
    last_message = state["messages"][-1]

    # (æ³¨æ„ï¼šAIMessage.tool_calls åœ¨ Langchain 0.1. tool_calls æ˜¯æ–°æ ‡å‡†)
    tool_calls = last_message.tool_calls

    # æ‰§è¡Œå·¥å…·
    tool_messages = []
    for call in tool_calls:
        tool_name = call['name']
        if tool_name not in tools_map:
            content = f"Error: Tool {tool_name} not found."
        elif tool_name == 'propose_new_vector':
            execution_args = call['args'].copy()
            execution_args['messages'] = state["messages"]
            execution_args['role_name'] = role
            output = tools_map[tool_name].invoke(execution_args)
            content = json.dumps(output)

        else:
            output = tools_map[tool_name].invoke(call['args'])  # call å·²ç»æ˜¯ (name, args) æ ¼å¼
            content = json.dumps(output)

        tool_messages.append(
            ToolMessage(content=content, tool_call_id=call['id'])
        )

        # è°ƒç”¨å·¥å…·åŽçš„è¾…åŠ©æŒ‡ä»¤
        if tool_name == 'propose_new_vector':
            # æ·»åŠ ç³»ç»ŸæŒ‡ä»¤ï¼Œè®©LLMå¯¹ç»“æžœè¿›è¡Œåˆ†æž
            instruction_message = HumanMessage(
                content=f"å·²æ”¶åˆ°æ–°æ–¹æ¡ˆæ•°æ®ï¼š{content}ã€‚\n"
                        f"è¯·**ä»”ç»†å¯¹æ¯”**æ–°æ–¹æ¡ˆçš„å¾—åˆ† (score_new) ä¸Žæ—§æ–¹æ¡ˆå¾—åˆ† (score_old)ã€‚\n"
                        f"ç„¶åŽæ ¹æ®å¯¹æ¯”ç»“æžœï¼Œè°ƒç”¨ `final_decision` ç»“æŸä»»åŠ¡ã€‚\n"
                        f"åœ¨è°ƒç”¨ `final_decision` æ—¶ï¼Œè¯·åŠ¡å¿…åœ¨ `justification` å­—æ®µä¸­è¯¦ç»†è¯´æ˜Žä¸¤ä¸ªåˆ†æ•°çš„å¯¹æ¯”æƒ…å†µã€‚")
            tool_messages.append(instruction_message)

    return {"messages": tool_messages}


def conditional_router(state: GraphState):
    """
    è·¯ç”±èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ (å¾ªçŽ¯æˆ–ç»“æŸ)
    """
    last_message = state["messages"][-1]

    # å¦‚æžœ LLM çš„ä¸Šä¸€æ­¥æ˜¯ AIMessage å¹¶ä¸”å®ƒè°ƒç”¨äº†å·¥å…·
    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        return "call_tools"
    else:
        # å¦åˆ™ (ä¾‹å¦‚å·¥å…·æ‰§è¡Œå®Œæ¯•åŽ)ï¼Œè¿”å›žç»™ Agent æ€è€ƒ
        return "call_agent"


def route_after_tools(state: GraphState):
    """
    å·¥å…·æ‰§è¡ŒåŽçš„è·¯ç”±ï¼šåˆ¤æ–­åˆšæ‰æ‰§è¡Œçš„å·¥å…·æ˜¯å¦æ˜¯ç»ˆæ­¢å·¥å…·ã€‚
    """
    messages = state["messages"]

    # å€’åºæŸ¥æ‰¾æœ€è¿‘çš„ä¸€æ¡ AI æ¶ˆæ¯ï¼ˆå®ƒè§¦å‘äº†å½“å‰çš„å·¥å…·æ‰§è¡Œï¼‰
    for msg in reversed(messages):
        if isinstance(msg, AIMessage):
            if msg.tool_calls and any(call['name'] == 'final_decision' for call in msg.tool_calls):
                return END
            break

    # å¦‚æžœæ²¡è°ƒç”¨ç»ˆæ­¢å·¥å…·ï¼Œåˆ™å›ž agent ç»§ç»­å¾ªçŽ¯
    return "agent"


class GraphAgent:
    def __init__(self, role: Literal['Government', 'Developer', 'Village'], metric: Literal['WSWM', 'wNBS'] = 'WSWM'):
        self.role = role
        self.metric = metric
        workflow = self._init_workflow()
        self.app = workflow.compile()
        self._optimize_prompt = OPTIMIZER_SYSTEM_PROMPT

    def _init_workflow(self):
        workflow = StateGraph(GraphState)
        # 2. æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("agent", agent_node)
        workflow.add_node("tools", self.tool_node)
        # 3. è®¾ç½®å…¥å£
        workflow.set_entry_point("agent")
        # 4. æ·»åŠ è¾¹
        workflow.add_conditional_edges(
            "agent",  # èµ·ç‚¹
            conditional_router,  # è·¯ç”±å‡½æ•°
            {
                "call_tools": "tools",  # å¦‚æžœè·¯ç”±è¿”å›ž "call_tools"ï¼Œåˆ™åŽ» "tools" èŠ‚ç‚¹
                "call_agent": "agent",  # å¦‚æžœè·¯ç”±è¿”å›ž "call_agent"ï¼Œåˆ™åŽ» "agent" èŠ‚ç‚¹
                END: END  # å¦‚æžœè·¯ç”±è¿”å›ž ENDï¼Œåˆ™ç»“æŸ
            }
        )
        workflow.add_conditional_edges(
            "tools",  # èµ·ç‚¹ï¼šå·¥å…·èŠ‚ç‚¹
            route_after_tools,  # è·¯ç”±å‡½æ•°ï¼šæ‰§è¡Œå®Œå·¥å…·åŽåˆ¤æ–­åŽ»å“ª
            {
                "agent": "agent",  # æƒ…å†µAï¼šæ™®é€šå·¥å…· -> å›ž Agent
                END: END  # æƒ…å†µBï¼šFinalDecision -> ç»“æŸ
            }
        )
        return workflow

    def tool_node(self, state: GraphState):
        """
        Tool èŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…· (æ‰‹è„š)
        """
        print(f"--- ðŸ› ï¸ Agent æ­£åœ¨è¡ŒåŠ¨... ---")
        # èŽ·å– LLM åˆšåˆšçš„å›žå¤
        last_message = state["messages"][-1]

        # (æ³¨æ„ï¼šAIMessage.tool_calls åœ¨ Langchain 0.1. tool_calls æ˜¯æ–°æ ‡å‡†)
        tool_calls = last_message.tool_calls

        # æ‰§è¡Œå·¥å…·
        tool_messages = []
        for call in tool_calls:
            tool_name = call['name']
            if tool_name not in tools_map:
                content = f"Error: Tool {tool_name} not found."
            elif tool_name == 'propose_new_vector':
                execution_args = call['args'].copy()
                execution_args['messages'] = state["messages"]
                execution_args['role_name'] = self.role
                output = tools_map[tool_name].invoke(execution_args)
                content = json.dumps(output)
            elif tool_name == 'evaluate_objective_function':
                execution_args = call['args'].copy()
                execution_args['metric'] = self.metric
                output = tools_map[tool_name].invoke(execution_args)
                content = json.dumps(output)
            else:
                output = tools_map[tool_name].invoke(call['args'])  # call å·²ç»æ˜¯ (name, args) æ ¼å¼
                content = json.dumps(output)

            tool_messages.append(
                ToolMessage(content=content, tool_call_id=call['id'])
            )

            # è°ƒç”¨å·¥å…·åŽçš„è¾…åŠ©æŒ‡ä»¤
            if tool_name == 'propose_new_vector':
                # æ·»åŠ ç³»ç»ŸæŒ‡ä»¤ï¼Œè®©LLMå¯¹ç»“æžœè¿›è¡Œåˆ†æž
                instruction_message = HumanMessage(
                    content=f"å·²æ”¶åˆ°æ–°æ–¹æ¡ˆæ•°æ®ï¼š{content}ã€‚\n"
                            f"è¯·**ä»”ç»†å¯¹æ¯”**æ–°æ–¹æ¡ˆçš„å¾—åˆ† (score_new) ä¸Žæ—§æ–¹æ¡ˆå¾—åˆ† (score_old)ã€‚\n"
                            f"ç„¶åŽæ ¹æ®å¯¹æ¯”ç»“æžœï¼Œè°ƒç”¨ `final_decision` ç»“æŸä»»åŠ¡ã€‚\n"
                            f"åœ¨è°ƒç”¨ `final_decision` æ—¶ï¼Œè¯·åŠ¡å¿…åœ¨ `justification` å­—æ®µä¸­è¯¦ç»†è¯´æ˜Žä¸¤ä¸ªåˆ†æ•°çš„å¯¹æ¯”æƒ…å†µã€‚")
                tool_messages.append(instruction_message)

        return {"messages": tool_messages}

    def invoke(self, vector: List[float]):
        initial_messages = [
            SystemMessage(content=self._optimize_prompt),
            HumanMessage(content=f"è¯·ä¼˜åŒ–è¿™ä¸ªå‘é‡: {vector}")
        ]
        final_state = self.app.invoke({"messages": initial_messages})
        latest_vector = vector

        for msg in reversed(final_state['messages']):
            if isinstance(msg, AIMessage) and msg.tool_calls:
                # æ£€æŸ¥æ˜¯å¦æœ‰ final_decision è°ƒç”¨
                final_call = next((call for call in msg.tool_calls if call['name'] == 'final_decision'), None)

                if final_call:
                    args = final_call['args']
                    # æå– final_vectorï¼Œå¦‚æžœæ²¡æœ‰åˆ™ä¿æŒåŽŸå€¼
                    if 'final_vector' in args:
                        latest_vector = args['final_vector']
                    break  # æ‰¾åˆ°åŽç«‹å³åœæ­¢

        return {'messages': final_state['messages'],
                'latest_vector': latest_vector,
                }


if __name__ == '__main__':
    # --- 6. æž„å»ºå¹¶è¿è¡Œå›¾ ---

    # 1. åˆ›å»ºå›¾
    workflow = StateGraph(GraphState)

    # 2. æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("agent", agent_node)
    workflow.add_node("tools", tool_node)

    # 3. è®¾ç½®å…¥å£
    workflow.set_entry_point("agent")

    # 4. æ·»åŠ è¾¹
    workflow.add_conditional_edges(
        "agent",  # èµ·ç‚¹
        conditional_router,  # è·¯ç”±å‡½æ•°
        {
            "call_tools": "tools",  # å¦‚æžœè·¯ç”±è¿”å›ž "call_tools"ï¼Œåˆ™åŽ» "tools" èŠ‚ç‚¹
            "call_agent": "agent",  # å¦‚æžœè·¯ç”±è¿”å›ž "call_agent"ï¼Œåˆ™åŽ» "agent" èŠ‚ç‚¹
            END: END  # å¦‚æžœè·¯ç”±è¿”å›ž ENDï¼Œåˆ™ç»“æŸ
        }
    )
    # workflow.add_edge("tools", "agent")  # å·¥å…·æ‰§è¡Œå®ŒåŽï¼Œæ€»æ˜¯è¿”å›žç»™ Agent æ€è€ƒ
    workflow.add_conditional_edges(
        "tools",  # èµ·ç‚¹ï¼šå·¥å…·èŠ‚ç‚¹
        route_after_tools,  # è·¯ç”±å‡½æ•°ï¼šæ‰§è¡Œå®Œå·¥å…·åŽåˆ¤æ–­åŽ»å“ª
        {
            "agent": "agent",  # æƒ…å†µAï¼šæ™®é€šå·¥å…· -> å›ž Agent
            END: END  # æƒ…å†µBï¼šFinalDecision -> ç»“æŸ
        }
    )

    # 5. ç¼–è¯‘å›¾
    app = workflow.compile()

    # 6. è¿è¡Œ Agentï¼
    print("--- ðŸš€ ä¼˜åŒ–å™¨ Agent å·²å¯åŠ¨ ---")

    # æ‚¨çš„è¾“å…¥å‘é‡ (æ¥è‡ª agent.py)
    input_vector = [75.91, 8.35, 32.77, 0.0, 0.20]

    # æˆ‘ä»¬é€šè¿‡è¾“å…¥æ¶ˆæ¯æ¥å¯åŠ¨ Agent
    role = "Government"
    round = 1
    total_round = 5
    initial_messages = [
        SystemMessage(content=OPTIMIZER_SYSTEM_PROMPT),
        HumanMessage(content=f"è¯·ä¼˜åŒ–è¿™ä¸ªå‘é‡: {input_vector}")
    ]

    # .stream() ä¼šè¿”å›žæ¯ä¸€æ­¥çš„çŠ¶æ€ï¼Œè®©æ‚¨å¯ä»¥çœ‹åˆ°å®Œæ•´çš„æ€è€ƒè¿‡ç¨‹
    # .invoke() åªä¼šè¿”å›žæœ€ç»ˆçŠ¶æ€
    final_state = app.invoke({"messages": initial_messages})

    print("\n--- âœ… æµç¨‹ç»“æŸ ---")
    print("æœ€ç»ˆçš„å¯¹è¯åŽ†å²:")
    for msg in final_state['messages']:
        if isinstance(msg, AIMessage) and msg.tool_calls:
            print(f"AI -> å†³å®šè°ƒç”¨å·¥å…·: {msg.tool_calls[0]['name']}({msg.tool_calls[0]['args']})")
        elif isinstance(msg, ToolMessage):
            print(f"å·¥å…· -> è¿”å›ž: {msg.content}")
